{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b55efc6-2fab-4077-9f65-cbc4577eed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 20:55:14,808 - hy3dgen.shapgen - INFO - Try to load model from local path: /root/.cache/hy3dgen/tencent/Hunyuan3D-2.1/hunyuan3d-dit-v2-1\n",
      "2025-08-02 20:55:14,815 - hy3dgen.shapgen - INFO - Loading model from /root/.cache/hy3dgen/tencent/Hunyuan3D-2.1/hunyuan3d-dit-v2-1/model.fp16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "PointCrossAttentionEncoder INFO: pc_sharpedge_size is zero\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddefb2d51d77462ea3162fed33ff67bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "from hy3dshape.pipelines import Hunyuan3DDiTFlowMatchingPipeline\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Инициализация моделей ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(\n",
    "    'tencent/Hunyuan3D-2.1',\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "image_gen_pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"playgroundai/playground-v2.5-1024px-aesthetic\",\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "# --- НОВАЯ ВСПОМОГАТЕЛЬНАЯ ФУНКЦИЯ ---\n",
    "def resize_and_pad(image: Image.Image, target_size: tuple[int, int], fill_color: tuple[int, int, int] = (255, 255, 255)) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Изменяет размер изображения, сохраняя пропорции, и добавляет поля до target_size.\n",
    "    \"\"\"\n",
    "    # Создаем новое квадратное изображение с заданным цветом фона\n",
    "    padded_image = Image.new(\"RGB\", target_size, fill_color)\n",
    "    \n",
    "    # Уменьшаем исходное изображение так, чтобы оно вписывалось в target_size\n",
    "    image.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Вычисляем позицию для центрирования\n",
    "    paste_position = (\n",
    "        (target_size[0] - image.width) // 2,\n",
    "        (target_size[1] - image.height) // 2\n",
    "    )\n",
    "    \n",
    "    # Вставляем уменьшенное изображение на фон\n",
    "    padded_image.paste(image, paste_position)\n",
    "    \n",
    "    return padded_image\n",
    "\n",
    "\n",
    "# --- 2. Обновленные функции генерации ---\n",
    "\n",
    "def generate_mesh_from_image(image_path: str, output_path: str):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Ошибка: Файл изображения не найден: {image_path}\")\n",
    "        return\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # ИСПОЛЬЗУЕМ НОВУЮ ФУНКЦИЮ ВМЕСТО ПРОСТОГО RESIZE\n",
    "    processed_image = resize_and_pad(image, (512, 512))\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # СОХРАНЯЕМ РЕФЕРЕНСНОЕ ИЗОБРАЖЕНИЕ\n",
    "    ref_image_path = os.path.splitext(output_path)[0] + '.png'\n",
    "    processed_image.save(ref_image_path)\n",
    "    print(f\"Референсное изображение сохранено: {ref_image_path}\")\n",
    "\n",
    "    generated_mesh = shape_pipeline(image=processed_image, show_progress_bar=False)[0]\n",
    "    generated_mesh.export(output_path)\n",
    "    \n",
    "    print(f\"Меш из изображения сохранен: {output_path}\")\n",
    "\n",
    "\n",
    "def generate_mesh_from_text(prompt: str, output_path: str):\n",
    "    image = image_gen_pipeline(prompt=prompt).images[0]\n",
    "    \n",
    "    # ИСПОЛЬЗУЕМ НОВУЮ ФУНКЦИЮ ВМЕСТО ПРОСТОГО RESIZE\n",
    "    processed_image = resize_and_pad(image, (512, 512))\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # СОХРАНЯЕМ РЕФЕРЕНСНОЕ ИЗОБРАЖЕНИЕ\n",
    "    ref_image_path = os.path.splitext(output_path)[0] + '.png'\n",
    "    processed_image.save(ref_image_path)\n",
    "    print(f\"Референсное изображение сохранено: {ref_image_path}\")\n",
    "\n",
    "    generated_mesh = shape_pipeline(image=processed_image, show_progress_bar=False)[0]\n",
    "    generated_mesh.export(output_path)\n",
    "    \n",
    "    print(f\"Меш из текста '{prompt}' сохранен: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0926c1-36cc-4a0e-a3f7-212bc51fb9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Референсное изображение сохранено: ../output/rebecca_one_piece_bikini.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|███████████████████████████████████| 50/50 [00:09<00:00,  5.35it/s]\n",
      "Volume Decoding: 100%|██████████████████████████████████| 7134/7134 [00:13<00:00, 513.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Меш из изображения сохранен: ../output/rebecca_one_piece_bikini.glb\n"
     ]
    }
   ],
   "source": [
    "generate_mesh_from_image(\n",
    "    image_path='../assets/d98mtp939hpc1.jpeg',\n",
    "    output_path='../output/rebecca_one_piece_bikini.glb'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1de45f0-aef6-452e-87f0-8c1d81a27210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f718172d3b4a6394f010f604753929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Референсное изображение сохранено: ../output/sword.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|███████████████████████████████████| 50/50 [00:08<00:00,  5.64it/s]\n",
      "Volume Decoding: 100%|██████████████████████████████████| 7134/7134 [00:13<00:00, 514.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Меш из текста '(masterpiece, best quality, 8k), (one single sword:1.5), a single ornate fantasy sword, solo object, centered, full body shot of a sword, detailed weapon, game asset, ((isolated on a pure white background)), flat lighting, no shadows' сохранен: ../output/sword.glb\n"
     ]
    }
   ],
   "source": [
    "generate_mesh_from_text(\n",
    "    prompt=\"(masterpiece), (best quality), game asset, a single longsword, front view, orthographic, 3d model, 3d render, hyper detailed, clean, ((white background)), ((isolated on white)), professional, studio lighting, sharp focus\",\n",
    "    output_path='../output/sword.glb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ed022f-c57b-4647-8889-9d69d791b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 13:14:50,873 - hy3dgen.shapgen - INFO - Try to load model from local path: /root/.cache/hy3dgen/tencent/Hunyuan3D-2.1/hunyuan3d-dit-v2-1\n",
      "2025-08-03 13:14:50,880 - hy3dgen.shapgen - INFO - Loading model from /root/.cache/hy3dgen/tencent/Hunyuan3D-2.1/hunyuan3d-dit-v2-1/model.fp16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Инициализация моделей...\n",
      "Используемое устройство: cuda\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "PointCrossAttentionEncoder INFO: pc_sharpedge_size is zero\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d9a0e6975649f8a8d6ddeebb0c02c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модели успешно инициализированы.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "from hy3dshape.pipelines import Hunyuan3DDiTFlowMatchingPipeline\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import warnings\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Инициализация моделей ---\n",
    "print(\"Инициализация моделей...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "\n",
    "shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(\n",
    "    'tencent/Hunyuan3D-2.1', torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "image_gen_pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"playgroundai/playground-v2.5-1024px-aesthetic\", torch_dtype=torch.float16, variant=\"fp16\"\n",
    ").to(device)\n",
    "\n",
    "print(\"Модели успешно инициализированы.\")\n",
    "\n",
    "\n",
    "# --- 2. Вспомогательные функции ---\n",
    "\n",
    "def resize_and_pad(image: Image.Image, target_size: tuple[int, int], fill_color: tuple[int, int, int] = (255, 255, 255)) -> Image.Image:\n",
    "    padded_image = Image.new(\"RGB\", target_size, fill_color)\n",
    "    image.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "    paste_position = ((target_size[0] - image.width) // 2, (target_size[1] - image.height) // 2)\n",
    "    padded_image.paste(image, paste_position)\n",
    "    return padded_image\n",
    "\n",
    "# ФУНКЦИЯ 1: УДАЛЕНИЕ \"ОСТРОВОВ\"\n",
    "def clean_mesh_by_largest_component(input_path: str, output_path: str) -> bool:\n",
    "    try:\n",
    "        print(f\"Шаг 1/2: Очистка от отдельных артефактов в {input_path}\")\n",
    "        mesh = trimesh.load_mesh(input_path, force='mesh')\n",
    "        if not isinstance(mesh, trimesh.Trimesh): return False\n",
    "        \n",
    "        components = mesh.split(only_watertight=False)\n",
    "        \n",
    "        if len(components) <= 1:\n",
    "            print(\"Меш уже состоит из одного компонента, очистка не требуется.\")\n",
    "            mesh.export(output_path)\n",
    "            return True\n",
    "            \n",
    "        print(f\"Найдено компонентов: {len(components)}. Выбираем самый большой.\")\n",
    "        largest_component = max(components, key=lambda c: len(c.faces))\n",
    "        largest_component.export(output_path)\n",
    "        print(f\"Очищенный high-poly меш сохранен: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Ошибка на шаге 1 (очистка компонентов): {e}\")\n",
    "        return False\n",
    "\n",
    "# ФУНКЦИЯ 2: УПРОЩЕНИЕ ДО LOW-POLY\n",
    "def decimate_mesh(input_path: str, output_path: str, target_face_count: int) -> bool:\n",
    "    try:\n",
    "        print(f\"Шаг 2/2: Упрощение до low-poly из {input_path}\")\n",
    "        mesh = trimesh.load_mesh(input_path, force='mesh')\n",
    "        if not isinstance(mesh, trimesh.Trimesh): return False\n",
    "        \n",
    "        if len(mesh.faces) <= target_face_count:\n",
    "            mesh.export(output_path)\n",
    "            return True\n",
    "        \n",
    "        new_mesh = mesh.simplify_quadric_decimation(face_count=target_face_count)\n",
    "        new_mesh.export(output_path)\n",
    "        print(f\"Финальный low-poly меш сохранен: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Ошибка на шаге 2 (упрощение): {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# --- 3. Основные конвейеры генерации ---\n",
    "\n",
    "def process_generated_mesh(raw_path, output_prefix, low_poly_faces):\n",
    "    \"\"\"Упрощенный конвейер постобработки.\"\"\"\n",
    "    cleaned_path = f\"{output_prefix}_1_cleaned_high.obj\"\n",
    "    final_low_poly_path = f\"{output_prefix}_2_final_low.obj\"\n",
    "\n",
    "    # Шаг удаления плоскости ПОЛНОСТЬЮ УДАЛЕН\n",
    "    if not clean_mesh_by_largest_component(raw_path, cleaned_path): return\n",
    "    if not decimate_mesh(cleaned_path, final_low_poly_path, target_face_count=low_poly_faces): return\n",
    "\n",
    "def generate_mesh_from_text(prompt: str, output_prefix: str, low_poly_faces: int = 1500):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Начало генерации из текста: '{prompt}'\")\n",
    "    try:\n",
    "        output_dir = os.path.dirname(output_prefix)\n",
    "        if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "        raw_path = f\"{output_prefix}_0_raw.obj\"\n",
    "\n",
    "        print(\"Генерация референсного изображения...\")\n",
    "        image = image_gen_pipeline(prompt=prompt, num_inference_steps=25).images[0]\n",
    "        processed_image = resize_and_pad(image, (512, 512))\n",
    "        \n",
    "        print(\"Генерация сырого 3D-меша...\")\n",
    "        generated_mesh = shape_pipeline(image=processed_image, show_progress_bar=True)[0]\n",
    "        generated_mesh.export(raw_path)\n",
    "        \n",
    "        process_generated_mesh(raw_path, output_prefix, low_poly_faces)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Произошла глобальная ошибка: {e}\")\n",
    "    print(\"Генерация завершена.\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "def generate_mesh_from_image(image_path: str, output_prefix: str, low_poly_faces: int = 1500):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Начало генерации из изображения: {image_path}\")\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"!!! Ошибка: Файл не найден {image_path}\")\n",
    "        return\n",
    "    try:\n",
    "        output_dir = os.path.dirname(output_prefix)\n",
    "        if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "        raw_path = f\"{output_prefix}_0_raw.obj\"\n",
    "\n",
    "        print(\"Обработка референсного изображения...\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        processed_image = resize_and_pad(image, (512, 512))\n",
    "        \n",
    "        print(\"Генерация сырого 3D-меша...\")\n",
    "        generated_mesh = shape_pipeline(image=processed_image, show_progress_bar=True)[0]\n",
    "        generated_mesh.export(raw_path)\n",
    "        \n",
    "        process_generated_mesh(raw_path, output_prefix, low_poly_faces)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Произошла глобальная ошибка: {e}\")\n",
    "    print(\"Генерация завершена.\")\n",
    "    print(\"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6ffe63-755d-4e50-9973-83dfb533197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Начало генерации из текста: '(masterpiece), (best quality), game asset, a single longsword, front view, orthographic, 3d model, 3d render, hyper detailed, clean, ((white background)), ((isolated on white)), professional, studio lighting, sharp focus'\n",
      "Генерация референсного изображения...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b7916a96f445508c0e635d14170d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация сырого 3D-меша...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|█████████████████████████████████████████| 50/50 [00:08<00:00,  5.57it/s]\n",
      "Volume Decoding: 100%|████████████████████████████████████████| 7134/7134 [00:13<00:00, 510.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шаг 1/2: Очистка от отдельных артефактов в ../output/sword_0_raw.obj\n",
      "Найдено компонентов: 5. Выбираем самый большой.\n",
      "Очищенный high-poly меш сохранен: ../output/sword_1_cleaned_high.obj\n",
      "Шаг 2/2: Упрощение до low-poly из ../output/sword_1_cleaned_high.obj\n",
      "Финальный low-poly меш сохранен: ../output/sword_2_final_low.obj\n",
      "Генерация завершена.\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Начало генерации из изображения: ../assets/photo_2025-08-03_13-08-51.jpg\n",
      "Обработка референсного изображения...\n",
      "Генерация сырого 3D-меша...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|█████████████████████████████████████████| 50/50 [00:09<00:00,  5.54it/s]\n",
      "Volume Decoding: 100%|████████████████████████████████████████| 7134/7134 [00:14<00:00, 507.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шаг 1/2: Очистка от отдельных артефактов в ../output/rebecca_test_0_raw.obj\n",
      "Найдено компонентов: 4. Выбираем самый большой.\n",
      "Очищенный high-poly меш сохранен: ../output/rebecca_test_1_cleaned_high.obj\n",
      "Шаг 2/2: Упрощение до low-poly из ../output/rebecca_test_1_cleaned_high.obj\n",
      "Финальный low-poly меш сохранен: ../output/rebecca_test_2_final_low.obj\n",
      "Генерация завершена.\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Создаем папку для результатов, если ее нет\n",
    "    if not os.path.exists('output'):\n",
    "        os.makedirs('output')\n",
    "\n",
    "    # --- Пример 1: Генерация из текстового запроса ---\n",
    "    # Вы можете менять prompt и количество полигонов (low_poly_faces)\n",
    "    generate_mesh_from_text(\n",
    "        prompt=\"(masterpiece), (best quality), game asset, a single longsword, front view, orthographic, 3d model, 3d render, hyper detailed, clean, ((white background)), ((isolated on white)), professional, studio lighting, sharp focus\",\n",
    "        output_prefix=\"../output/sword\",\n",
    "        low_poly_faces=1000  # Устанавливаем желаемое количество полигонов\n",
    "    )\n",
    "\n",
    "    # --- Пример 2: Генерация из файла ---\n",
    "    # Чтобы использовать этот пример:\n",
    "    # 1. Создайте файл 'my_image.png' в той же папке, что и скрипт.\n",
    "    # 2. Раскомментируйте строки ниже.\n",
    "    \n",
    "    # image_file = '../assets/photo_2025-08-03_13-08-51.jpg'\n",
    "    # if os.path.exists(image_file):\n",
    "    #     generate_mesh_from_image(\n",
    "    #         image_path=image_file,\n",
    "    #         output_prefix=\"../output/rebecca_test\",\n",
    "    #         low_poly_faces=2000 # Другое значение для примера\n",
    "    #     )\n",
    "    # else:\n",
    "    #     print(f\"Для запуска примера 2 создайте файл с именем '{image_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7892f59c-3284-4e4c-9e32-f00cbe35dad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 13:28:25,637 - hy3dgen.shapgen - INFO - Try to load model from local path: /root/.cache/hy3dgen/tencent/Hunyuan3D-2.1/hunyuan3d-dit-v2-1\n",
      "2025-08-03 13:28:25,643 - hy3dgen.shapgen - INFO - Loading model from /root/.cache/hy3dgen/tencent/Hunyuan3D-2.1/hunyuan3d-dit-v2-1/model.fp16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Инициализация моделей...\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "using moe\n",
      "PointCrossAttentionEncoder INFO: pc_sharpedge_size is zero\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ed93a1d49b4dad9d479b2d5cf76c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модели успешно инициализированы.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baa5165d95a47efafcfd395d5a66d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|█████████████████████████████████████████| 50/50 [00:08<00:00,  5.66it/s]\n",
      "Volume Decoding: 100%|████████████████████████████████████████| 7134/7134 [00:13<00:00, 517.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация для '../output/sword_imp_g' завершена.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "from hy3dshape.pipelines import Hunyuan3DDiTFlowMatchingPipeline\n",
    "from PIL import Image, ImageOps\n",
    "from rembg import remove\n",
    "import os\n",
    "import warnings\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Инициализация моделей ---\n",
    "print(\"Инициализация моделей...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(\n",
    "    'tencent/Hunyuan3D-2.1', torch_dtype=torch.float16\n",
    ")\n",
    "image_gen_pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"playgroundai/playground-v2.5-1024px-aesthetic\", torch_dtype=torch.float16, variant=\"fp16\"\n",
    ").to(device)\n",
    "print(\"Модели успешно инициализированы.\")\n",
    "\n",
    "# --- 2. Вспомогательные функции ---\n",
    "\n",
    "def resize_and_pad(image: Image.Image, target_size: tuple[int, int], fill_color: tuple[int, int, int] = (255, 255, 255)) -> Image.Image:\n",
    "    padded_image = Image.new(\"RGB\", target_size, fill_color)\n",
    "    image.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "    paste_position = ((target_size[0] - image.width) // 2, (target_size[1] - image.height) // 2)\n",
    "    padded_image.paste(image, paste_position)\n",
    "    return padded_image\n",
    "\n",
    "def clean_mesh_by_largest_component(input_path: str, output_path: str) -> bool:\n",
    "    try:\n",
    "        mesh = trimesh.load_mesh(input_path, force='mesh')\n",
    "        if not isinstance(mesh, trimesh.Trimesh): return False\n",
    "        components = mesh.split(only_watertight=False)\n",
    "        if len(components) <= 1:\n",
    "            mesh.export(output_path)\n",
    "            return True\n",
    "        largest_component = max(components, key=lambda c: len(c.faces))\n",
    "        largest_component.export(output_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при очистке меша: {e}\")\n",
    "        return False\n",
    "\n",
    "def decimate_mesh(input_path: str, output_path: str, target_face_count: int) -> bool:\n",
    "    try:\n",
    "        mesh = trimesh.load_mesh(input_path, force='mesh')\n",
    "        if not isinstance(mesh, trimesh.Trimesh): return False\n",
    "        if len(mesh.faces) <= target_face_count:\n",
    "            mesh.export(output_path)\n",
    "            return True\n",
    "        new_mesh = mesh.simplify_quadric_decimation(face_count=target_face_count)\n",
    "        new_mesh.export(output_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при упрощении меша: {e}\")\n",
    "        return False\n",
    "\n",
    "def process_generated_mesh(raw_path, output_prefix, low_poly_faces):\n",
    "    cleaned_path = f\"{output_prefix}_1_cleaned_high.obj\"\n",
    "    final_low_poly_path = f\"{output_prefix}_2_final_low.obj\"\n",
    "    if not clean_mesh_by_largest_component(raw_path, cleaned_path): return\n",
    "    if not decimate_mesh(cleaned_path, final_low_poly_path, target_face_count=low_poly_faces): return\n",
    "\n",
    "# --- 3. Основной конвейер генерации ---\n",
    "\n",
    "def generate_mesh_from_text(\n",
    "    prompt: str,\n",
    "    output_prefix: str,\n",
    "    low_poly_faces: int = 1500,\n",
    "    seed: int = 42,\n",
    "    num_inference_steps: int = 50,\n",
    "    guidance_scale: float = 3.5\n",
    "):\n",
    "    try:\n",
    "        output_dir = os.path.dirname(output_prefix)\n",
    "        if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "        raw_path = f\"{output_prefix}_0_raw.obj\"\n",
    "\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        image = image_gen_pipeline(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator\n",
    "        ).images[0]\n",
    "\n",
    "        image_no_bg_rgba = remove(image)\n",
    "        white_background = Image.new(\"RGB\", image_no_bg_rgba.size, (255, 255, 255))\n",
    "        white_background.paste(image_no_bg_rgba, (0, 0), image_no_bg_rgba)\n",
    "        \n",
    "        image_on_white = white_background\n",
    "        image_on_white.save(f\"{output_prefix}_reference_image.png\")\n",
    "        \n",
    "        processed_image = resize_and_pad(image_on_white, (512, 512))\n",
    "        \n",
    "        generated_mesh = shape_pipeline(image=processed_image, show_progress_bar=True)[0]\n",
    "        generated_mesh.export(raw_path)\n",
    "        \n",
    "        process_generated_mesh(raw_path, output_prefix, low_poly_faces)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла глобальная ошибка: {e}\")\n",
    "    print(f\"Генерация для '{output_prefix}' завершена.\")\n",
    "\n",
    "\n",
    "# --- 4. Точка входа и пример использования ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    output_folder = \"results_3d\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Промпт для генерации объекта на белом фоне\n",
    "    generate_mesh_from_text(\n",
    "        prompt=\"(masterpiece), (best quality), game asset, a single longsword, front view, orthographic, 3d model, 3d render, hyper detailed, clean, ((white background)), ((isolated on white)), professional, studio lighting, sharp focus\",\n",
    "        output_prefix=\"../output/sword_imp_g\",\n",
    "        low_poly_faces=1000  # Устанавливаем желаемое количество полигонов\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c5dbc0f-9a7c-4261-bc4d-1cdd66b54825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234fcedea2644e91aaf902f0d80b1cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion Sampling:: 100%|█████████████████████████████████████████| 50/50 [00:08<00:00,  5.57it/s]\n",
      "Volume Decoding: 100%|████████████████████████████████████████| 7134/7134 [00:13<00:00, 512.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация для '../output/dragon' завершена.\n"
     ]
    }
   ],
   "source": [
    "generate_mesh_from_text(\n",
    "    prompt=\"photorealistic 3d model of a mechanical dragon, steampunk style, single object, centered, uniform pure white background, no shadow, studio lighting, product shot, 8k\",\n",
    "    output_prefix=\"../output/dragon\",\n",
    "    low_poly_faces=2000  # Устанавливаем желаемое количество полигонов\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
